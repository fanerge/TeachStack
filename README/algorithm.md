# 基础

数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

## 复杂度分析

### 大 O 复杂度表示法

```
T(n) = O(f(n))
T(n)表示代码执行的时间
n 表示数据规模的大小
f(n) 表示每行代码执行的次数总和
```

### 时间复杂度（渐进时间复杂度）分析

代码执行时间随数据规模增长的变化趋势。

1.  只关注循环执行次数最多的一段代码
2.  加法法则：总复杂度等于量级最大的那段代码的复杂度
3.  乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

```
O(1) // 常量阶
O(logn)、O(nlogn) // 对数阶，（归并排序、快速排序）
O(m+n)、O(m*n) // 多个循环并列或嵌套
```

### 空间复杂度（渐进空间复杂度）分析

我们说空间复杂度，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

算法的执行时间与数据规模之间的增长关系。
代码执行需要申请空间的大小。

```
O(1) // 只需要常量级空间
O(1)、O(logn)、O(n)、O(nlogn)、O(n2)
```

### 最好、最坏、平均、均摊时间复杂度

```
最好情况时间复杂度（best case time complexity）:最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。
最坏情况时间复杂度（worst case time complexity）:最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。
平均情况时间复杂度（average case time complexity）:平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。（需要为增加每种情况出现的概率）
均摊时间复杂度（amortized time complexity）:摊还分析法
```

# 数据结构

## 数组（Array）

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。<br>
线性表（Linear List）：线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。<br>
非线性表：比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

### 随机访问数组快的原因？

```
const a:any[] = [];
大部分数组都是连续空间，base_address为初始地址，下标是相对于初始地址的offset，所以通过公式
一维数组内存寻址：a[i]_address = base_address + i * data_type_size
可以很快求出i的存放地址，所以随机访问速度快。
// 二维数组内存寻址
对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：
a[i]_address = base_address + (i * n + j) * data_type_size
```

### 数组的“插入”和“删除”低效？

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k ～ n 这部分的元素都顺序地往后挪一位。

## 链表（Linked list）

链表并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。

### 单链表

我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址叫作后继指针 next，尾结点的指针指向空地址 NULL。

### 循环链表

它跟单链表唯一的区别就在尾结点。
尾结点特殊的地方是：单链表指针指向一个空地址 NULL，而循环链表的尾结点指针是指向链表的头结点。

### 双向链表（应用比较广）

它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。

### 双向循环链表

循环链表 + 双向链表

### 双向链表删除操作比单链表快？

虽然删除操作的时间复杂度是 O(1)，但是需要遍历去找需要删除元素（删除结点中“值等于某个给定值”的结点、删除给定指针指向的结点）。<br>
对于删除结点中“值等于某个给定值”的结点，单链表需要遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。
删除给定指针指向的结点，单链表没有 prev 指针所以并不支持直接获取前驱结点，所以为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。

### 如何用链表来实现 LRU 缓存淘汰策略呢？

LRU 是 Least Recently Used 的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况：如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

### 写链表代码技巧

1.  理解指针或引用的含义：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
2.  警惕指针丢失和内存泄漏，删除链表结点时，也一定要记得手动释放内存空间
3.  利用哨兵简化实现难度
4.  重点留意边界条件处理
5.  举例画图，辅助思考

#### 哨兵（Sentinel）

在许多算法中，存在“邻居依赖问题”（我自己造的词），在处理当前元素时，要涉及到它旁边那个元素。那如果当前元素是边界元素呢，它没有旁边那个元素，如果不作处理，程序就可能出错；如果对它特别对待，就会增加代码复杂性，还会降低程序效率。应用哨兵，也就是申请若干个多余的元素作为边界元素的邻居，可以完美得解决这个问题。

```
// 删除链表节点
// 题目描述：给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。返回删除后的链表的头节点。
var deleteNode = function(head, val) {
    let pre = new ListNode(-1); // 哨兵节点
    pre.next = head;

    let node = pre;
    while (node.next) {
        if (node.next.val === val) {
            node.next = node.next.next;
            break;
        }
        node = node.next;
    }
    return pre.next;
};
```

重点留意边界条件处理

```
如果链表为空时，代码是否能正常工作？
如果链表只包含一个结点时，代码是否能正常工作？
如果链表只包含两个结点时，代码是否能正常工作？
代码逻辑在处理头结点和尾结点的时候，是否能正常工作？
```

指针丢失

```
// 例如在a结点和b结点中插入x结点（避免指针丢失，应该将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。 ）
p->next = x;  // 将p的next指针指向x结点；// 指针迎接丢失了
x->next = p->next;  // 将x的结点的next指针指向b结点；
```

### 常见的链表考题

```
单链表反转
链表中环的检测
两个有序的链表合并
删除链表倒数第 n 个结点
求链表的中间结点
```

#### 单链表操作

针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。

```
// 空链表插入
if (head == null) {  head = new_node;}
// 非空链表插入
new_node->next = p->next;p->next = new_node;
// 空链表删除
if (head->next == null) { head = null;}
// 非空链表删除
p->next = p->next->next;
```

引入哨兵结点，解决上面的问题

```
如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。
因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。
```

## 栈（Stack）

栈只支持两个基本操作：入栈 push()和出栈 pop()。
后进者先出，先进者后出，这就是典型的“栈”结构。<br>
当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

### 栈在函数调用中的应用

1.  函数调用栈
2.  表达式求值

```
编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。
如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。
```

3.  括号匹配
4.  浏览器的前进和后退功能/微信小程序路由管理

```
两个栈即可实现（分别放前进后退）
```

## 队列（Queue）

先进者先出，这就是典型的“队列”。
两个操作：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。

### 循环队列

顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在我们把首尾相连，扳成了一个环。
想写出没有 bug 的循环队列的实现代码，我个人觉得，最关键的是，确定好队空和队满的判定条件。

### 阻塞队列

阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

### 并发队列

最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。

## 递归（Recursion）

递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。<br>
空间耗费就翻倍了。

### 递归需要满足的三个条件（同时满足）

1. 一个问题的解可以分解为几个子问题的解
2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
3. 存在递归终止条件

### 如何编写递归代码？

写出递推公式，找到终止条件。<br>
编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。<br>
递归代码要警惕堆栈溢出。<br>
递归代码要警惕重复计算。<br>
将递归代码改写为非递归代码？迭代循环<br>

## 排序（Sort）

冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。

### 如何分析一个“排序算法”？

1.  排序算法的执行效率
2.  排序算法的内存消耗
3.  排序算法的稳定性

### 平方排序 O(n^2)

#### 冒泡排序（Bubble Sort）

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。<br>
当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。

##### 有序度

有序度是数组中具有有序关系的元素对的个数。

```
有序元素对：a[i] <= a[j], 如果i < j。
满有序度 = n*(n-1)/2
逆序度 = 满有序度 - 有序度
元素交换的次数是一个固定值，是原始数据的逆序度。
```

#### 插入排序（Insertion Sort）

一个有序的数组，我们往里面添加一个新的数据后，我们只要遍历数组，找到数据应该插入的位置将其插入即可。

### 对数排序 O(nlogn)

#### 选择排序（Selection Sort）

选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。

#### 归并排序（Merge Sort）

归并排序使用的就是分治思想。
如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。

```
递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))
终止条件：p >= r 不用再继续分解

merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟A[p...r]一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++等于i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }

  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r

  // 将剩余的数据拷贝到临时数组tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }

  // 将tmp中的数组拷贝回A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

### 快速排序（Quick Sort）

如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。
我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。

```
递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1… r)
终止条件：p >= r

// 快速排序，A是数组，n表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r为下标
quick_sort_c(A, p, r) {
  if p >= r then return

  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
```

### 线性排序算法（都趋近于 O(n)）

#### 桶排序（Bucket sort）

核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。<br>
桶排序比较适合用在外部排序中。<br>

#### 计数排序（Counting sort）

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。<br>
计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

#### 基数排序（Radix sort）

假如我们需要给 11 位手机号排序，先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。<br>
基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

### 排序优化

#### 如何实现一个通用的、高性能的排序函数？

Glibc 中的 qsort() 函数：
qsort() 数据量小时会优先使用归并排序来排序输入数据，
qsort() 数据量大时会改为用快速排序算法来排序，
元素的个数小于等于 4 时，qsort() 就退化为插入排序，不再继续用递归来做快速排序，
使用哨兵来简化代码

## 查找算法

### 二分查找（Binary Search）

二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。<br>
T(n) = O(logn) <br>
适用于有序数组（随机访问速度要快）、静态数据（无频繁的插入、删除操作）、数据太小不适合<br>
容易出错的地方：循环退出条件、mid 的取值，low 和 high 的更新。<br>

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;

  while (low <= high) {
    int mid = (low + high) / 2;
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }

  return -1;
}
```

### 如何快速定位 IP 对应的省份地址？

容易出错：终止条件、区间上下界更新方法、返回值选择。

变体一：查找第一个值等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == 0) || (a[mid - 1] != value)) return mid;
      else high = mid - 1;
    }
  }
  return -1;
}
```

变体二：查找最后一个值等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] != value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
```

变体三：查找第一个大于等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] >= value) {
      if ((mid == 0) || (a[mid - 1] < value)) return mid;
      else high = mid - 1;
    } else {
      low = mid + 1;
    }
  }
  return -1;
}
```

变体四：查找最后一个小于等于给定值的元素

```

public int bsearch7(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] > value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
```

### Skip List（动态数据结构）

我们需要对链表稍加改造（对链表建立多级有间隔的“索引”），就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫作跳表（Skip list）。<br>
跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。<br>
Skip List = Link List + 多级索引。<br>
跳表的空间复杂度是 O(n)<br>

#### 为什么 Redis 要用跳表来实现有序集合，而不是红黑树？

```
插入一个数据；
删除一个数据；
查找一个数据；
按照区间查找数据（比如查找值在[100, 356]之间的数据）； // 按照区间来查找数据这个操作，红黑树的效率没有跳表高。
迭代输出有序序列。
```

## 散列表（Hash Table）

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。<br>
散列表三个部分组成：键（key）、散列函数、散列值。
散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。<br>

### 装载因子（load factor）

散列表的装载因子=填入表中的元素个数/散列表的长度<br>
装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

### 散列函数设计的基本要求

1.  散列函数计算得到的散列值是一个非负整数；
2.  如果 key1 = key2，那 hash(key1) == hash(key2)；
3.  如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。

### 散列冲突解决方法

1.  开放寻址法
    开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。
2.  二次探测（Quadratic probing）
    如果出现了散列冲突，间隔为平方级
3.  双重散列（Double hashing）
    使用多个散列函数
4.  链表法
    在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

### Word 文档中的单词拼写检查功能是如何实现的？

当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。

### 如何打造一个工业级水平的散列表？

#### 选择好的散列函数

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等

#### 均摊扩容

当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。
当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。
这期间的查询操作怎么来做呢？对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。
通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。

#### 选择解决散列冲突的方法

当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的 ThreadLocalMap 使用开放寻址法解决散列冲突的原因。<br>
基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

## 哈希算法（Hash Algorithm）

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

### 哈希算法条件

1.  从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
2.  对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
3.  散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
4.  哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

### 哈希算法应用

分别是安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

#### 安全加密

MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）
SHA（Secure Hash Algorithm，安全散列算法）
DES（Data Encryption Standard，数据加密标准）
AES（Advanced Encryption Standard，高级加密标准）

#### 唯一标识

我们可以给每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

#### 为什么哈希算法无法做到零冲突？

我们知道，哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。这里你应该能想到，一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

#### 数据校验

我们通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

#### 散列函数

散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

### 如何防止数据库中的用户信息被脱库？

我们可以通过哈希算法，对用户密码进行加密之后再存储，不过最好选择相对安全的加密算法，比如 SHA 等（因为 MD5 已经号称被破解了）。还需要防止字典攻击。<br>
针对字典攻击，我们可以引入一个盐（salt），跟用户的密码组合在一起，增加密码的复杂度。我们拿组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。<br>
字典攻击，在破解密码或密钥时，逐一尝试用户自定义词典中的可能密码（单词或短语）的攻击方式。那我们就需要维护一个常用密码的字典表，把字典中的每个密码用哈希算法计算哈希值，然后拿哈希值跟脱库后的密文比对。如果相同，基本上就可以认为，这个加密之后的密码对应的明文就是字典中的这个密码。

# 算法方法

## 枚举（部分枚举）

基于已有知识进行答案猜测的一种问题求解策略。
队列为空的判断条件仍然是 head == tail。

### 解题思路

小于 N 的最大‘素数‘，”百钱百鸡”，“熄灯问题”，“讨厌的青蛙”

1.  给出解空间，建立简洁的数学模型（素数的定义）
2.  减少搜索的空间（除 2 以外，只有奇数才有可能为解）
3.  采用合适的搜索顺序空间（从小到大，最大的那一个就为解）

## 递推（类似于求通项公式）

通过已知条件，利用特定关系得出中间推论，直至得到结果的算法。递推算法分为顺推和逆推两种。

### 解题思路

从原点出发，一步只能向右走、向上走或向左走。恰好走 N 步且不经过已走的点共有多少种走法？

```
N = 1时，f(1)=3
N = 2时，f(2)=7
N = 3时，f(3)=17
...
f(n) = 2*f(n-1)+f(n-2) (n>=3)
```

## 递归

某个函数直接或间接的调用自身，把一个问题逐级分解成子问题<br>
背后的数据结构为栈

### 解题思路

斐波那契数列、阶乘、汉诺塔问题、棋盘切割等

1.  递归方程，如何将原问题划分成子问题
2.  递归出口，递归终止的条件，即最小子问题的求解，可以允许多个出口
3.  边界函数，问题规模变化的函数，它保证递归的规模向出口靠拢

## 分治算法（属于递归系列）

分治和动规的区别，分解出的子问题是不重复的使用分治法，如果有的问题分解后的子问题有重复的（重叠子问题性质），的使用动规。<br>
基本思想是将一个规模为 N 的问题分解为 K 个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。<br>
二分法属于分治。

### 解题思路

最经典的归并排序为例，它把待排序数组不断二分为规模更小的子问题处理，这就是“分而治之”这个词的由来。

## 动态规划（属于递归系列）

[LeetCode 探索初级算法 - 动态规划](http://zhuanlan.zhihu.com/p/49427827)

避免递归中的重复计算，将之前的计算结果保存下来
三个概念：最优子结构、边界、状态转移方程。<br>
一般自底向上更容易理解。

```
// 10步楼梯走法，每次只能走一步或两步
// f(10) = f(9) + f(8);因此，f(9)和f(8)是f(10)的「最优子结构」
// f(1) = 1; f(2) = 2;因此，f(1)、f(2)是问题的「边界」
// f(n) = f(n-1) + f(n-2);被称为「状态转移方程」
```

[10 步楼梯走法](https://juejin.im/post/5a29d52cf265da43333e4da7)

### 解题思路

数字三角形、最长公共子序列

1.  寻找状态转移方程（状态转移方程是第 N 项与前若干项之间的关系）
2.  利用状态转移方程式“自底向上”求解问题
3.  边界条件

#### 递归转动规的一般转化方法

递归函数有 n 个参数，就定义一个 n 维的数组，数组的下标是递归函数参数的取值范围，数组元素的值是递归函数的返回值，这样就可以从边界值开始，逐步填充数组，相当于计算递归函数值的逆过程。

## 回溯法

有些实际问题很难归纳出一组简单的递推公式或直观的求解步骤，并且也不能进行无限的列举。对于这类问题，一种有效的方法是“试”。通过对问题的分析，找出一个解决问题的线索，然后沿着这个线索逐步试探，对于每一步试探，若试探成功，就得到问题的解，若试探失败，就逐步回退，换别的路线再进行试探。这种方法称为回朔法。
