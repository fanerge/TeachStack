# 基础

数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

## 复杂度分析

### 大 O 复杂度表示法

```
T(n) = O(f(n))
T(n)表示代码执行的时间
n 表示数据规模的大小
f(n) 表示每行代码执行的次数总和
```

### 时间复杂度（渐进时间复杂度）分析

代码执行时间随数据规模增长的变化趋势。

1.  只关注循环执行次数最多的一段代码
2.  加法法则：总复杂度等于量级最大的那段代码的复杂度
3.  乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

```
O(1) // 常量阶
O(logn)、O(nlogn) // 对数阶，（归并排序、快速排序）
O(m+n)、O(m*n) // 多个循环并列或嵌套
```

### 空间复杂度（渐进空间复杂度）分析

我们说空间复杂度，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

算法的执行时间与数据规模之间的增长关系。
代码执行需要申请空间的大小。

```
O(1) // 只需要常量级空间
O(1)、O(logn)、O(n)、O(nlogn)、O(n2)
```

### 最好、最坏、平均、均摊时间复杂度

```
最好情况时间复杂度（best case time complexity）:最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。
最坏情况时间复杂度（worst case time complexity）:最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。
平均情况时间复杂度（average case time complexity）:平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。（需要为增加每种情况出现的概率）
均摊时间复杂度（amortized time complexity）:摊还分析法
```

# 数据结构

## 数组（Array）

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。<br>
线性表（Linear List）：线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。<br>
非线性表：比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

### 随机访问数组快的原因？

```
const a:any[] = [];
大部分数组都是连续空间，base_address为初始地址，下标是相对于初始地址的offset，所以通过公式
一维数组内存寻址：a[i]_address = base_address + i * data_type_size
可以很快求出i的存放地址，所以随机访问速度快。
// 二维数组内存寻址
对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：
a[i]_address = base_address + (i * n + j) * data_type_size
```

### 数组的“插入”和“删除”低效？

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k ～ n 这部分的元素都顺序地往后挪一位。

## 链表（Linked list）

链表并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。

### 单链表

我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址叫作后继指针 next，尾结点的指针指向空地址 NULL。

### 循环链表

它跟单链表唯一的区别就在尾结点。
尾结点特殊的地方是：单链表指针指向一个空地址 NULL，而循环链表的尾结点指针是指向链表的头结点。

### 双向链表（应用比较广）

它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。

### 双向循环链表

循环链表 + 双向链表

### 双向链表删除操作比单链表快？

虽然删除操作的时间复杂度是 O(1)，但是需要遍历去找需要删除元素（删除结点中“值等于某个给定值”的结点、删除给定指针指向的结点）。<br>
对于删除结点中“值等于某个给定值”的结点，单链表需要遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。
删除给定指针指向的结点，单链表没有 prev 指针所以并不支持直接获取前驱结点，所以为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。

### 如何用链表来实现 LRU 缓存淘汰策略呢？

LRU 是 Least Recently Used 的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况：如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

### 写链表代码技巧

1.  理解指针或引用的含义：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
2.  警惕指针丢失和内存泄漏，删除链表结点时，也一定要记得手动释放内存空间
3.  利用哨兵简化实现难度
4.  重点留意边界条件处理
5.  举例画图，辅助思考

#### 哨兵（Sentinel）

在许多算法中，存在“邻居依赖问题”（我自己造的词），在处理当前元素时，要涉及到它旁边那个元素。那如果当前元素是边界元素呢，它没有旁边那个元素，如果不作处理，程序就可能出错；如果对它特别对待，就会增加代码复杂性，还会降低程序效率。应用哨兵，也就是申请若干个多余的元素作为边界元素的邻居，可以完美得解决这个问题。

```
// 删除链表节点
// 题目描述：给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。返回删除后的链表的头节点。
var deleteNode = function(head, val) {
    let pre = new ListNode(-1); // 哨兵节点
    pre.next = head;

    let node = pre;
    while (node.next) {
        if (node.next.val === val) {
            node.next = node.next.next;
            break;
        }
        node = node.next;
    }
    return pre.next;
};
```

重点留意边界条件处理

```
如果链表为空时，代码是否能正常工作？
如果链表只包含一个结点时，代码是否能正常工作？
如果链表只包含两个结点时，代码是否能正常工作？
代码逻辑在处理头结点和尾结点的时候，是否能正常工作？
```

指针丢失

```
// 例如在a结点和b结点中插入x结点（避免指针丢失，应该将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。 ）
p->next = x;  // 将p的next指针指向x结点；// 指针迎接丢失了
x->next = p->next;  // 将x的结点的next指针指向b结点；
```

### 常见的链表考题

```
单链表反转
链表中环的检测
两个有序的链表合并
删除链表倒数第 n 个结点
求链表的中间结点
```

#### 单链表操作

针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。

```
// 空链表插入
if (head == null) {  head = new_node;}
// 非空链表插入
new_node->next = p->next;p->next = new_node;
// 空链表删除
if (head->next == null) { head = null;}
// 非空链表删除
p->next = p->next->next;
```

引入哨兵结点，解决上面的问题

```
如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。
因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。
```

## 栈（Stack）

栈只支持两个基本操作：入栈 push()和出栈 pop()。
后进者先出，先进者后出，这就是典型的“栈”结构。<br>
当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

### 栈在函数调用中的应用

1.  函数调用栈
2.  表达式求值

```
编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。
如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。
```

3.  括号匹配
4.  浏览器的前进和后退功能/微信小程序路由管理

```
两个栈即可实现（分别放前进后退）
```

## 队列（Queue）

先进者先出，这就是典型的“队列”。
两个操作：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。

### 循环队列

顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在我们把首尾相连，扳成了一个环。
想写出没有 bug 的循环队列的实现代码，我个人觉得，最关键的是，确定好队空和队满的判定条件。

### 阻塞队列

阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

### 并发队列

最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。

## 递归（Recursion）

递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。<br>
空间耗费就翻倍了。

### 递归需要满足的三个条件（同时满足）

1. 一个问题的解可以分解为几个子问题的解
2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
3. 存在递归终止条件

### 如何编写递归代码？

写出递推公式，找到终止条件。<br>
编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。<br>
递归代码要警惕堆栈溢出。<br>
递归代码要警惕重复计算。<br>
将递归代码改写为非递归代码？迭代循环<br>

## 排序（Sort）

冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。

### 如何分析一个“排序算法”？

1.  排序算法的执行效率
2.  排序算法的内存消耗
3.  排序算法的稳定性

### 平方排序 O(n^2)

#### 冒泡排序（Bubble Sort）

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。<br>
当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。

##### 有序度

有序度是数组中具有有序关系的元素对的个数。

```
有序元素对：a[i] <= a[j], 如果i < j。
满有序度 = n*(n-1)/2
逆序度 = 满有序度 - 有序度
元素交换的次数是一个固定值，是原始数据的逆序度。
```

#### 插入排序（Insertion Sort）

一个有序的数组，我们往里面添加一个新的数据后，我们只要遍历数组，找到数据应该插入的位置将其插入即可。

### 对数排序 O(nlogn)

#### 选择排序（Selection Sort）

选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。

#### 归并排序（Merge Sort）

归并排序使用的就是分治思想。
如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。

```
递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))
终止条件：p >= r 不用再继续分解

merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟A[p...r]一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++等于i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }

  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r

  // 将剩余的数据拷贝到临时数组tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }

  // 将tmp中的数组拷贝回A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

### 快速排序（Quick Sort）

如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。
我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。

```
递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1… r)
终止条件：p >= r

// 快速排序，A是数组，n表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r为下标
quick_sort_c(A, p, r) {
  if p >= r then return

  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
```

### 线性排序算法（都趋近于 O(n)）

#### 桶排序（Bucket sort）

核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。<br>
桶排序比较适合用在外部排序中。<br>

#### 计数排序（Counting sort）

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。<br>
计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

#### 基数排序（Radix sort）

假如我们需要给 11 位手机号排序，先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。<br>
基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

### 排序优化

#### 如何实现一个通用的、高性能的排序函数？

Glibc 中的 qsort() 函数：
qsort() 数据量小时会优先使用归并排序来排序输入数据，
qsort() 数据量大时会改为用快速排序算法来排序，
元素的个数小于等于 4 时，qsort() 就退化为插入排序，不再继续用递归来做快速排序，
使用哨兵来简化代码

## 查找算法

### 二分查找（Binary Search）

二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。<br>
T(n) = O(logn) <br>
适用于有序数组（随机访问速度要快）、静态数据（无频繁的插入、删除操作）、数据太小不适合<br>
容易出错的地方：循环退出条件、mid 的取值，low 和 high 的更新。<br>

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;

  while (low <= high) {
    int mid = (low + high) / 2;
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }

  return -1;
}
```

### 如何快速定位 IP 对应的省份地址？

容易出错：终止条件、区间上下界更新方法、返回值选择。

变体一：查找第一个值等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == 0) || (a[mid - 1] != value)) return mid;
      else high = mid - 1;
    }
  }
  return -1;
}
```

变体二：查找最后一个值等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] != value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
```

变体三：查找第一个大于等于给定值的元素

```

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] >= value) {
      if ((mid == 0) || (a[mid - 1] < value)) return mid;
      else high = mid - 1;
    } else {
      low = mid + 1;
    }
  }
  return -1;
}
```

变体四：查找最后一个小于等于给定值的元素

```

public int bsearch7(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] > value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
```

### Skip List（动态数据结构）

我们需要对链表稍加改造（对链表建立多级有间隔的“索引”），就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫作跳表（Skip list）。<br>
跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。<br>
Skip List = Link List + 多级索引。<br>
跳表的空间复杂度是 O(n)<br>

#### 为什么 Redis 要用跳表来实现有序集合，而不是红黑树？

```
插入一个数据；
删除一个数据；
查找一个数据；
按照区间查找数据（比如查找值在[100, 356]之间的数据）； // 按照区间来查找数据这个操作，红黑树的效率没有跳表高。
迭代输出有序序列。
```

## 散列表（Hash Table）

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。<br>
散列表三个部分组成：键（key）、散列函数、散列值。
散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。<br>

### 装载因子（load factor）

散列表的装载因子=填入表中的元素个数/散列表的长度<br>
装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

### 散列函数设计的基本要求

1.  散列函数计算得到的散列值是一个非负整数；
2.  如果 key1 = key2，那 hash(key1) == hash(key2)；
3.  如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。

### 散列冲突解决方法

1.  开放寻址法
    开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。
2.  二次探测（Quadratic probing）
    如果出现了散列冲突，间隔为平方级
3.  双重散列（Double hashing）
    使用多个散列函数
4.  链表法
    在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

### Word 文档中的单词拼写检查功能是如何实现的？

当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。

### 如何打造一个工业级水平的散列表？

#### 选择好的散列函数

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等

#### 均摊扩容

当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。
当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。
这期间的查询操作怎么来做呢？对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。
通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。

#### 选择解决散列冲突的方法

当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的 ThreadLocalMap 使用开放寻址法解决散列冲突的原因。<br>
基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

## 哈希算法（Hash Algorithm）

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。

### 哈希算法条件

1.  从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；
2.  对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
3.  散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
4.  哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

### 哈希算法应用

分别是安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

#### 安全加密

MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）
SHA（Secure Hash Algorithm，安全散列算法）
DES（Data Encryption Standard，数据加密标准）
AES（Advanced Encryption Standard，高级加密标准）

#### 唯一标识

我们可以给每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

#### 为什么哈希算法无法做到零冲突？

我们知道，哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。这里你应该能想到，一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

#### 数据校验

我们通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

#### 散列函数

散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

### 如何防止数据库中的用户信息被脱库？

我们可以通过哈希算法，对用户密码进行加密之后再存储，不过最好选择相对安全的加密算法，比如 SHA 等（因为 MD5 已经号称被破解了）。还需要防止字典攻击。<br>
针对字典攻击，我们可以引入一个盐（salt），跟用户的密码组合在一起，增加密码的复杂度。我们拿组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。<br>
字典攻击，在破解密码或密钥时，逐一尝试用户自定义词典中的可能密码（单词或短语）的攻击方式。那我们就需要维护一个常用密码的字典表，把字典中的每个密码用哈希算法计算哈希值，然后拿哈希值跟脱库后的密文比对。如果相同，基本上就可以认为，这个加密之后的密码对应的明文就是字典中的这个密码。

### 哈希算法在分布式系统中有哪些应用？

#### 负载均衡

负载均衡算法有很多，比如轮询、随机、加权轮询等。<br>
我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

## 二叉树（Binary Tree）

高度（Height）：节点到叶子节点的最长路径（边树）
深度（Depth）：根节点到这个节点所经历的边数
层（Level）：节点的深度 + 1

### 满二叉树

叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫作满二叉树。

### 完全二叉树

叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作完全二叉树。
数组

### 二叉树的遍历

相对于根节点来说。<br>
写递推公式的关键就是，如果要解决问题 A，就假设子问题 B、C 已经解决，然后再来看如何利用 B、C 来解决 A。<br>
二叉树的便利，每个节点最多会被访问两次，所以二叉树遍历的时间复杂度是 O(n)

#### 前序遍历（根左右）

```

void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印root节点
  preOrder(root->left);
  preOrder(root->right);
}
```

#### 中序遍历（左根右）

```
void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印root节点
  inOrder(root->right);
}


```

#### 后序遍历（左右根）

```
void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印root节点
}
```

### 二叉查找树（Binary Search Tree）

二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。顾名思义，二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。
时间复杂度：间复杂度是 O(logn)。

#### 二叉查找树的定义

二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

#### 二叉查找树的操作

##### 查找

如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。

##### 插入

如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。

##### 删除

针对要删除节点的子节点个数的不同，我们需要分三种情况来处理。
第一种情况是，如果要删除的节点没有子节点，我们只需要直接将父节点中，指向要删除节点的指针置为 null。
第二种情况是，如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。
第三种情况是，如果要删除的节点有两个子节点，这就比较复杂了。我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，我们可以应用上面两条规则来删除这个最小节点。
实际上，关于二叉查找树的删除操作，还有个非常简单、取巧的方法，就是单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。

##### 其他操作

快速地查找最大节点和最小节点、前驱节点和后继节点。

```

public class BinarySearchTree {
  private Node tree;

  public static class Node {
    private int data;
    private Node left;
    private Node right;

    public Node(int data) {
      this.data = data;
    }
  }

  // 查找
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }

  // 插入
  public void insert(int data) {
    if (tree == null) {
      tree = new Node(data);
      return;
    }

    Node p = tree;
    while (p != null) {
      if (data > p.data) {
        if (p.right == null) {
          p.right = new Node(data);
          return;
        }
        p = p.right;
      } else { // data < p.data
        if (p.left == null) {
          p.left = new Node(data);
          return;
        }
        p = p.left;
      }
    }
  }

  // 删除
  public void delete(int data) {
    Node p = tree; // p指向要删除的节点，初始化指向根节点
    Node pp = null; // pp记录的是p的父节点
    while (p != null && p.data != data) {
      pp = p;
      if (data > p.data) p = p.right;
      else p = p.left;
    }
    if (p == null) return; // 没有找到

    // 要删除的节点有两个子节点
    if (p.left != null && p.right != null) { // 查找右子树中最小节点
      Node minP = p.right;
      Node minPP = p; // minPP表示minP的父节点
      while (minP.left != null) {
        minPP = minP;
        minP = minP.left;
      }
      p.data = minP.data; // 将minP的数据替换到p中
      p = minP; // 下面就变成了删除minP了
      pp = minPP;
    }

    // 删除节点是叶子节点或者仅有一个子节点
    Node child; // p的子节点
    if (p.left != null) child = p.left;
    else if (p.right != null) child = p.right;
    else child = null;

    if (pp == null) tree = child; // 删除的是根节点
    else if (pp.left == p) pp.left = child;
    else pp.right = child;
  }
}
```

### 支持重复数据的二叉查找树

第一种方法比较容易。二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。
第二种方法比较不好理解。每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。

### 平衡二叉查找树

二叉树中任意一个节点的左右子树的高度相差不能大于 1。从这个定义来看，上一节我们讲的完全二叉树、满二叉树其实都是平衡二叉树，但是非完全二叉树也有可能是平衡二叉树。<br>
平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。

#### 红黑树（Red Black Tree）

红黑树的英文是“Red-Black Tree”，简称 R-B Tree。
一棵红黑树还需要满足这样几个要求：<br>
根节点是黑色的；
每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；
任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；
每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

##### 红黑树关注点

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。
因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它。

#### 自平衡二叉查找树（AVL tree）

AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是，有利就有弊，AVL 树为了维持这种高度的平衡，就要付出更多的代价。每次插入、删除都要做调整，就比较复杂、耗时。所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。

### 递归树（Recursion Tree）

借助递归树来分析递归算法的时间复杂度？

### 二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？

一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。
完全二叉树，适合用数组来存储，节省内存。

### 有了如此高效的散列表，为什么还需要二叉树？

第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。
第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。

### 为什么工程中都用红黑树这种二叉树？

红黑树的插入、删除、查找各种操作性能都比较稳定。对于工程应用来说，要面对各种异常情况，为了支撑这种工业级的应用，我们更倾向于这种性能稳定的平衡二叉查找树。

## 堆（Heap）

堆是一种特殊的树。
堆的应用，堆排序（建堆和排序）、从大数量级数据中筛选出 top n 条数据、根据不同优先级来处理网络请求。

### 堆的定义

堆是一个完全二叉树（数组存放）；
堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

### 堆的分类

对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”。
对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。

### 堆测操作（大根堆）

插入和删除时间复杂度为 O(logn)
因为数的高度为 log 以 2 为底 n 的对数，每次比较最多需要数的高度次。<i>
假设当前节点 index 为 i，则其左孩子 index 为 2*i+1，右孩子 index 为 2*i+2

#### 往堆中插入一个元素（insert）

1.  在堆的最后新建一个节点
2.  将数值赋予新节点
3.  将其节点和父节点比较
4.  如果新节点的数值比父节点大，调换父子节点的位置
5.  重复步骤 3 和 4 直到最大堆的特性被满足

#### 堆中移除根节点（poll）

1.  移除根节点
2.  将最后的元素移到根节点处
3.  将子节点和父节点比较
4.  如果父节点的数值比子节点数值小
5.  重复步骤 3 和 4 直到最大堆的特性被满足

```

public class Heap {
  private int[] a; // 数组，从下标1开始存储数据
  private int n;  // 堆可以存储的最大数据个数
  private int count; // 堆中已经存储的数据个数

  public Heap(int capacity) {
    a = new int[capacity + 1];
    n = capacity;
    count = 0;
  }

  public void insert(int data) {
    if (count >= n) return; // 堆满了
    ++count;
    a[count] = data;
    int i = count;
    while (i/2 > 0 && a[i] > a[i/2]) { // 自下往上堆化
      swap(a, i, i/2); // swap()函数作用：交换下标为i和i/2的两个元素
      i = i/2;
    }
  }

  public void removeMax() {
    if (count == 0) return -1; // 堆中没有数据
    a[1] = a[count];
    --count;
    heapify(a, count, 1);
  }

  private void heapify(int[] a, int n, int i) { // 自上往下堆化
    while (true) {
      int maxPos = i;
      if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
      if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
      if (maxPos == i) break;
      swap(a, i, maxPos);
      i = maxPos;
    }
  }
}
```

### 如何快速获取到 Top 10 最热门的搜索关键词？

一类是针对静态数据集合，也就是说数据集合事先确定，不会再变。另一类是针对动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中。

#### 静态数据

针对静态数据，如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？我们可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。

#### 动态数据

我们可以一直都维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，我们都可以立刻返回给他。

## 图（Graph）

```
顶点（vertex）：树中的元素我们称为节点，图中的元素我们就顶点（vertex）。
边（edge）：顶点可以与任意其他顶点。
顶点的度（degree）：顶点相连接的边的条数。
我们把这种边有方向的图叫作“有向图”。
我们把边没有方向的图就叫作“无向图”。
顶点的入度，表示有多少条边指向这个顶点。
顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。
带权图（weighted graph）每条边都有一个权重（weight）。
```

### 图的存储

#### 邻接矩阵存储方法

邻接矩阵的底层依赖一个二维数组。
用邻接矩阵来表示一个图，虽然简单、直观，但是比较浪费存储空间（特别是无向图和稀疏图（Sparse Matrix））。
邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。
用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。

#### 邻接表存储方法

邻接表存储类似于 HashTable 和 LinkList。
邻接表存储方法中每个顶点都对应一个链表，存储与其相连接的其他顶点。
邻接表还有改进升级版，即将链表换成更加高效的动态数据结构，比如平衡二叉查找树、跳表、散列表等。

### 如何存储微博、微信等社交网络中的好友关系？

因为社交网络是一张稀疏图，使用邻接矩阵存储比较浪费存储空间。所以，这里我们采用邻接表来存储。
邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系。

### 深度和广度优先搜索

深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构的。

```
public class Graph { // 无向图
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表

  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }

  public void addEdge(int s, int t) { // 无向图一条边存两次
    adj[s].add(t);
    adj[t].add(s);
  }
}

public void bfs(int s, int t) {
  if (s == t) return;
  boolean[] visited = new boolean[v];
  visited[s]=true;
  Queue<Integer> queue = new LinkedList<>();
  queue.add(s);
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  while (queue.size() != 0) {
    int w = queue.poll();
   for (int i = 0; i < adj[w].size(); ++i) {
      int q = adj[w].get(i);
      if (!visited[q]) {
        prev[q] = w;
        if (q == t) {
          print(prev, s, t);
          return;
        }
        visited[q] = true;
        queue.add(q);
      }
    }
  }
}

private void print(int[] prev, int s, int t) { // 递归打印s->t的路径
  if (prev[t] != -1 && t != s) {
    print(prev, s, prev[t]);
  }
  System.out.print(t + " ");
}
```

#### 广度优先搜索（Breadth-First-Search）

广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数。广度优先搜索的空间消耗主要在几个辅助变量 visited 数组、queue 队列、prev 数组上。这三个存储空间的大小都不会超过顶点的个数，所以空间复杂度是 O(V)。

#### 深度优先搜索（Depth-First-Search）

图上的深度优先搜索算法的时间复杂度是 O(E)，E 表示边的个数。
深度优先搜索算法的消耗内存主要是 visited、prev 数组和递归调用栈。visited、prev 数组的大小跟顶点的个数 V 成正比，递归调用栈的最大深度不会超过顶点的个数，所以总的空间复杂度就是 O(V)。

```

boolean found = false; // 全局变量或者类成员变量

public void dfs(int s, int t) {
  found = false;
  boolean[] visited = new boolean[v];
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  recurDfs(s, t, visited, prev);
  print(prev, s, t);
}

private void recurDfs(int w, int t, boolean[] visited, int[] prev) {
  if (found == true) return;
  visited[w] = true;
  if (w == t) {
    found = true;
    return;
  }
  for (int i = 0; i < adj[w].size(); ++i) {
    int q = adj[w].get(i);
    if (!visited[q]) {
      prev[q] = w;
      recurDfs(q, t, visited, prev);
    }
  }
}
```

### 如何找出社交网络中的三度好友关系？

这个问题就非常适合用图的广度优先搜索算法来解决，因为广度优先搜索是层层往外推进的。首先，遍历与起始顶点最近的一层顶点，也就是用户的一度好友，然后再遍历与用户距离的边数为 2 的顶点，也就是二度好友关系，以及与用户距离的边数为 3 的顶点，也就是三度好友关系。
我们只需要稍加改造一下广度优先搜索代码，用一个数组来记录每个顶点与起始顶点的距离，非常容易就可以找出三度好友关系。

## 字符串匹配

BF 算法和 RK 算法。

### BF 算法

定义：我们在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。
BF 算法中的 BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。
主串和模式串：在字符串 A 中查找字符串 B，那字符串 A 就是主串，字符串 B 就是模式串。

### RK 算法

RK 算法的全称叫 Rabin-Karp 算法。
整个 RK 算法包含两部分，计算子串哈希值和模式串哈希值与子串哈希值之间的比较。第一部分，我们前面也分析了，可以通过设计特殊的哈希算法，只需要扫描一遍主串就能计算出所有子串的哈希值了，所以这部分的时间复杂度是 O(n)。模式串哈希值与每个子串哈希值之间的比较的时间复杂度是 O(1)，总共需要比较 n-m+1 个子串的哈希值，所以，这部分的时间复杂度也是 O(n)。所以，RK 算法整体的时间复杂度就是 O(n)。

### BM（Boyer-Moore）算法

BM 算法包含两部分，分别是坏字符规则（bad character rule）和好后缀规则（good suffix shift）。
坏字符规则：我们从模式串的末尾往前倒着匹配，当我们发现某个字符没法匹配的时候。我们把这个没有匹配的字符叫作坏字符（主串中的字符）。

好后缀规则：

### KMP 算法

Knuth Morris Pratt 算法

### 字典树（Trie 树）

Trie 树，也叫“字典树”。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。
Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。

#### 如何实现一棵 Trie 树？

Trie 树主要有两个操作，一个是将字符串集合构造成 Trie 树。这个过程分解开来的话，就是一个将字符串插入到 Trie 树的过程。另一个是在 Trie 树中查询一个字符串。

```

public class Trie {
  private TrieNode root = new TrieNode('/'); // 存储无意义字符

  // 往Trie树中插入一个字符串
  public void insert(char[] text) {
    TrieNode p = root;
    for (int i = 0; i < text.length; ++i) {
      int index = text[i] - 'a';
      if (p.children[index] == null) {
        TrieNode newNode = new TrieNode(text[i]);
        p.children[index] = newNode;
      }
      p = p.children[index];
    }
    p.isEndingChar = true;
  }

  // 在Trie树中查找一个字符串
  public boolean find(char[] pattern) {
    TrieNode p = root;
    for (int i = 0; i < pattern.length; ++i) {
      int index = pattern[i] - 'a';
      if (p.children[index] == null) {
        return false; // 不存在pattern
      }
      p = p.children[index];
    }
    if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
    else return true; // 找到pattern
  }

  public class TrieNode {
    public char data;
    public TrieNode[] children = new TrieNode[26];
    public boolean isEndingChar = false;
    public TrieNode(char data) {
      this.data = data;
    }
  }
}
```

构建 Trie 树的过程，需要扫描所有的字符串，时间复杂度是 O(n)（n 表示所有字符串的长度和）。但是一旦构建成功之后，后续的查询操作会非常高效。

### 如何借助哈希算法实现高效字符串匹配？

BF 算法 和 RK 算法

### 如何实现文本编辑器中的查找功能？

BM（Boyer-Moore）算法

#### 如何实现搜索引擎的搜索关键词提示功能？

Trie 树比较适合的是查找前缀匹配的字符串。

### AC 自动机算法

全称是 Aho-Corasick 算法。
AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。

```
将多个模式串构建成 Trie 树；
在 Trie 树上构建失败指针（相当于 KMP 中的失效函数 next 数组）。
```

#### 如何用多模式串匹配实现敏感词过滤功能？

Aho-Corasick 算法。

## Greedy Algorithm（贪心算法）

贪心算法、分治算法、回溯算法、动态规划。更加确切地说，它们应该是算法思想，并不是具体的算法，常用来指导我们设计具体的算法和编码等。
贪心算法有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。

### 解题步骤

1.  第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。
2.  第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。
3.  第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。

贪心算法解决问题的思路，并不总能给出最优解。

### 案例

分糖果、钱币找零、区间覆盖

### 如何用贪心算法实现霍夫曼编码？

霍夫曼编码不仅会考察文本中有多少个不同字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。
霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。
根据贪心的思想，我们可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。

## 分治算法（Divide and Conquer）

### 如何理解分治算法？

分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。

### 解题步骤

1.  分解：将原问题分解成一系列子问题；
2.  解决：递归地求解各个子问题，若子问题足够小，则直接求解；
3.  合并：将子问题的结果合并成原问题。

### 分治算法能解决的问题，一般需要满足下面这几个条件

1.  原问题与分解成的小问题具有相同的模式；
2.  原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别。
3.  具有分解终止条件，也就是说，当问题足够小时，可以直接求解；
4.  可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。

## 回溯算法（Back tracking Algorithm）

回溯算法很多时候都应用在“搜索”这类问题上。

### 理解回溯算法？

回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。

### 1.0-1 背包\正则表达式

我们有一个背包，背包总的承载重量是 Wkg。现在我们有 n 个物品，每个物品的重量不等，并且不可分割。我们现在期望选择几件物品，装载到背包中。在不超过背包所能装载重量的前提下，如何让背包中物品的总重量最大？

#### 解题思路

我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。

```

public int maxW = Integer.MIN_VALUE; //存储背包中物品总重量的最大值
// cw表示当前已经装进去的物品的重量和；i表示考察到哪个物品了；
// w背包重量；items表示每个物品的重量；n表示物品个数
// 假设背包可承受重量100，物品个数10，物品重量存储在数组a中，那可以这样调用函数：
// f(0, 0, a, 10, 100)
public void f(int i, int cw, int[] items, int n, int w) {
  if (cw == w || i == n) { // cw==w表示装满了;i==n表示已经考察完所有的物品
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw, items, n, w);
  if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
    f(i+1,cw + items[i], items, n, w);
  }
}
```

## 动态规划（Dynamic Programming）

动态规划比较适合用来求解最优问题，比如求最大值、最小值等等。它可以非常显著地降低时间复杂度，提高代码的执行效率。
动态规划是一种空间换时间的解决思路。

### 0-1 背包问题

我们把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个物品决策（放入或者不放入背包）完之后，背包中的物品的重量会有多种情况，也就是说，会达到多种不同的状态，对应到递归树中，就是有很多不同的节点。

```
weight:物品重量，n:物品个数，w:背包可承载重量
public int knapsack(int[] weight, int n, int w) {
  boolean[][] states = new boolean[n][w+1]; // 默认值false
  states[0][0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (weight[0] <= w) {
    states[0][weight[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划状态转移
    for (int j = 0; j <= w; ++j) {// 不把第i个物品放入背包
      if (states[i-1][j] == true) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) {//把第i个物品放入背包
      if (states[i-1][j]==true) states[i][j+weight[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[n-1][i] == true) return i;
  }
  return 0;
}
```

### 什么样的问题可以用动态规划解决？

一个模型三个特征

1.  最优子结构
    最优子结构指的是，问题的最优解包含子问题的最优解。
    后面阶段的状态可以通过前面阶段的状态推导出来。
2.  无后效性
    在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。
    某阶段状态一旦确定，就不受之后阶段的决策影响。
3.  重复子问题
    不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

### 如何实现搜索引擎中的拼写纠错功能？

当用户在搜索框内，输入一个拼写错误的单词时，我们就拿这个单词跟词库中的单词一一进行比较，计算编辑距离，将编辑距离最小的单词，作为纠正之后的单词，提示给用户。<br>
莱文斯坦距离（Levenshtein distance），允许增加、删除、替换字符这三个编辑操作。<br>
最长公共子串长度（Longest common substring length），最长公共子串长度只允许增加、删除字符这两个编辑操作。<br>

## 拓扑排序（Topological Sorting）

拓扑排序本身就是基于有向无环图的一个算法。
解题方法 Kahn 算法和 DFS 深度优先搜索算法。

### 可以解决哪些问题

凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。
拓扑排序还能检测图中环的存在。对于 Kahn 算法来说，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环。
如何确定代码源文件的编译依赖关系？

### Kahn 算法

Kahn 算法实际上用的是贪心算法思想。
定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。
我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中（对应代码中就是把它打印出来），并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。

```

public void topoSortByKahn() {
  int[] inDegree = new int[v]; // 统计每个顶点的入度
  for (int i = 0; i < v; ++i) {
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inDegree[w]++;
    }
  }
  LinkedList<Integer> queue = new LinkedList<>();
  for (int i = 0; i < v; ++i) {
    if (inDegree[i] == 0) queue.add(i);
  }
  while (!queue.isEmpty()) {
    int i = queue.remove();
    System.out.print("->" + i);
    for (int j = 0; j < adj[i].size(); ++j) {
      int k = adj[i].get(j);
      inDegree[k]--;
      if (inDegree[k] == 0) queue.add(k);
    }
  }
}
```

### DFS 算法

第一部分是通过邻接表构造逆邻接表。邻接表中，边 s->t 表示 s 先于 t 执行，也就是 t 要依赖 s。在逆邻接表中，边 s->t 表示 s 依赖于 t，s 后于 t 执行。为什么这么转化呢？这个跟我们这个算法的实现思想有关。第二部分是这个算法的核心，也就是递归处理每个顶点。对于顶点 vertex 来说，我们先输出它可达的所有顶点，也就是说，先把它依赖的所有的顶点输出了，然后再输出自己。

```

public void topoSortByDFS() {
  // 先构建逆邻接表，边s->t表示，s依赖于t，t先于s
  LinkedList<Integer> inverseAdj[] = new LinkedList[v];
  for (int i = 0; i < v; ++i) { // 申请空间
    inverseAdj[i] = new LinkedList<>();
  }
  for (int i = 0; i < v; ++i) { // 通过邻接表生成逆邻接表
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inverseAdj[w].add(i); // w->i
    }
  }
  boolean[] visited = new boolean[v];
  for (int i = 0; i < v; ++i) { // 深度优先遍历图
    if (visited[i] == false) {
      visited[i] = true;
      dfs(i, inverseAdj, visited);
    }
  }
}

private void dfs(
    int vertex, LinkedList<Integer> inverseAdj[], boolean[] visited) {
  for (int i = 0; i < inverseAdj[vertex].size(); ++i) {
    int w = inverseAdj[vertex].get(i);
    if (visited[w] == true) continue;
    visited[w] = true;
    dfs(w, inverseAdj, visited);
  } // 先把vertex这个顶点可达的所有顶点都打印出来之后，再打印它自己
  System.out.print("->" + vertex);
}
```

## 地图软件是如何计算出最优出行路径的？

地图软件的路线规划问题讲起，带你看看常用的最短路径算法（Shortest Path Algorithm）。
Dijkstra 最短路径算法

## 如何实现网页爬虫中的 URL 去重功能？

布隆过滤器（Bloom Filter），有判错的概率
位图（BitMap）。因为，布隆过滤器本身就是基于位图的，是对位图的一种改进。
位图、布隆过滤器，来过滤重复的数据。

## 如何利用朴素贝叶斯算法过滤垃圾短信？

基于黑名单的过滤器
基于规则的过滤器
基于概率统计的过滤器（基于朴素贝叶斯算法）

## 如何实现一个简单的音乐推荐系统？

找到跟你口味偏好相似的用户，把他们爱听的歌曲推荐给你；
找出跟你喜爱的歌曲特征相似的歌曲，把这些歌曲推荐给你。
欧几里得距离是用来计算两个向量之间的距离的。
推荐系统（Recommendation System），大多可以通过欧几里得距离来实现，欧几里得距离越小就说明越相似。

## MySQL 数据库索引是如何实现的？

为了加速数据库中数据的查找速度，我们常用的处理思路是，对表中数据创建索引。
数据库索引实现，依赖的底层数据结构，B+ 树。它通过存储在磁盘的多叉树结构，做到了时间、空间的平衡，既保证了执行效率，又节省了内存。

## 如何用实现游戏中的寻路功能？

A*搜索算法
A* 算法属于一种启发式搜索算法（Heuristically Search Algorithm）。
曼哈顿距离是两点之间横纵坐标的距离之和。

## 如何在海量数据中快速查找某个数据？

索引
索引，你可以类比书籍的目录来理解。如果没有目录，我们想要查找某个知识点的时候，就要一页一页翻。通过目录，我们就可以快速定位相关知识点的页数，查找的速度也会有质的提高。

## 如何利用并行处理提高算法的执行效率？

并行算法（Parallel Algorithm）
对数据进行分片，对没有依赖关系的任务，并行地执行。

## 剖析搜索引擎背后的经典数据结构和算法

搜索引擎大致可以分为四个部分：搜集、分析、索引、查询。其中，搜集，就是我们常说的利用爬虫爬取网页。分析，主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作。索引，主要负责通过分析阶段得到的临时索引，构建倒排索引。查询，主要负责响应用户的请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。

## 剖析高性能队列 Disruptor 背后的数据结构和算法

它是一种内存消息队列。从功能上讲，它其实有点儿类似 Kafka。不过，和 Kafka 不同的是，Disruptor 是线程之间用于消息传递的队列。

## 剖析微服务接口鉴权限流背后的数据结构和算法

### 如何实现精确匹配规则？

我们先来看最简单的一种匹配模式。只有当请求 URL 跟规则中配置的某个接口精确匹配时，这个请求才会被接受、处理。

### 如何实现前缀匹配规则？

Trie 树中的每个节点不是存储单个字符，而是存储接口被“/”分割之后的子目录（比如“/user/name”被分割为“user”“name”两个子目录）。

### 限流背景介绍

固定时间窗口限流算法，首先我们需要选定一个时间起点，之后每当有接口请求到来，我们就将计数器加一。如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次访问请求），出现累加访问次数超过限流值的情况时，我们就拒绝后续的访问请求。当进入下一个时间窗口之后，计数器就清零重新计数。<br>
这种基于固定时间窗口的限流算法的缺点是，限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。<br>
滑动时间窗口限流算法，流量经过滑动时间窗口限流算法整形之后，可以保证任意一个 1s 的时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑。<br>

## 如何用学过的数据结构和算法实现一个短网址系统？

MurmurHash 算法

### 如何避免冲突

我们可以给原始网址拼接一串特殊字符，比如“[DUPLICATED]”，然后跟再重新计算哈希值，两次哈希计算都冲突的概率，显然是非常低的。假设出现非常极端的情况，又发生冲突了，我们可以再换一个拼接字符串，比如“[OHMYGOD]”，再计算哈希值。然后把计算得到的哈希值，跟原始网址拼接了特殊字符串之后的文本，一并存储在 MySQL 数据库中。

# 算法方法

## 枚举（部分枚举）

基于已有知识进行答案猜测的一种问题求解策略。
队列为空的判断条件仍然是 head == tail。

### 解题思路

小于 N 的最大‘素数‘，”百钱百鸡”，“熄灯问题”，“讨厌的青蛙”

1.  给出解空间，建立简洁的数学模型（素数的定义）
2.  减少搜索的空间（除 2 以外，只有奇数才有可能为解）
3.  采用合适的搜索顺序空间（从小到大，最大的那一个就为解）

## 递推（类似于求通项公式）

通过已知条件，利用特定关系得出中间推论，直至得到结果的算法。递推算法分为顺推和逆推两种。

### 解题思路

从原点出发，一步只能向右走、向上走或向左走。恰好走 N 步且不经过已走的点共有多少种走法？

```
N = 1时，f(1)=3
N = 2时，f(2)=7
N = 3时，f(3)=17
...
f(n) = 2*f(n-1)+f(n-2) (n>=3)
```

## 递归

某个函数直接或间接的调用自身，把一个问题逐级分解成子问题<br>
背后的数据结构为栈

### 解题思路

斐波那契数列、阶乘、汉诺塔问题、棋盘切割等

1.  递归方程，如何将原问题划分成子问题
2.  递归出口，递归终止的条件，即最小子问题的求解，可以允许多个出口
3.  边界函数，问题规模变化的函数，它保证递归的规模向出口靠拢

## 分治算法（属于递归系列）

分治和动规的区别，分解出的子问题是不重复的使用分治法，如果有的问题分解后的子问题有重复的（重叠子问题性质），的使用动规。<br>
基本思想是将一个规模为 N 的问题分解为 K 个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。<br>
二分法属于分治。

### 解题思路

最经典的归并排序为例，它把待排序数组不断二分为规模更小的子问题处理，这就是“分而治之”这个词的由来。

## 动态规划（属于递归系列）

[LeetCode 探索初级算法 - 动态规划](http://zhuanlan.zhihu.com/p/49427827)

避免递归中的重复计算，将之前的计算结果保存下来
三个概念：最优子结构、边界、状态转移方程。<br>
一般自底向上更容易理解。

```
// 10步楼梯走法，每次只能走一步或两步
// f(10) = f(9) + f(8);因此，f(9)和f(8)是f(10)的「最优子结构」
// f(1) = 1; f(2) = 2;因此，f(1)、f(2)是问题的「边界」
// f(n) = f(n-1) + f(n-2);被称为「状态转移方程」
```

[10 步楼梯走法](https://juejin.im/post/5a29d52cf265da43333e4da7)

### 解题思路

数字三角形、最长公共子序列

1.  寻找状态转移方程（状态转移方程是第 N 项与前若干项之间的关系）
2.  利用状态转移方程式“自底向上”求解问题
3.  边界条件

#### 递归转动规的一般转化方法

递归函数有 n 个参数，就定义一个 n 维的数组，数组的下标是递归函数参数的取值范围，数组元素的值是递归函数的返回值，这样就可以从边界值开始，逐步填充数组，相当于计算递归函数值的逆过程。

## 回溯法

有些实际问题很难归纳出一组简单的递推公式或直观的求解步骤，并且也不能进行无限的列举。对于这类问题，一种有效的方法是“试”。通过对问题的分析，找出一个解决问题的线索，然后沿着这个线索逐步试探，对于每一步试探，若试探成功，就得到问题的解，若试探失败，就逐步回退，换别的路线再进行试探。这种方法称为回朔法。
